# Meta-Learning-PaperReading

Notes for daily reading papers

### Have Read


| No. | Abb.| title | pdf | code | Brief| 
| :-: | :-: |:-: | :-: | :-: | :-:|
|1. | MTL |Meta-Transfer Learning for Few-Shot Learning|[CVPR 2019](https://arxiv.org/abs/1812.02391v2) | [Pytorch](https://github.com/y2l/meta-transfer-learning-pytorch) | Meta-learning; classification |
|2. | ACE |ACE: Adapting to Changing Environments for Semantic Segmentation|[ICCV 2019](https://arxiv.org/abs/1904.06268) | [No]() | DA; Meta-learning;Lifelong Learning; Segmentation |
|3. | IADA |Incremental Adversarial Domain Adaptation for Continually Changing Environments|[ICRA 2018](https://arxiv.org/abs/1712.07436) | [Pytorch](https://github.com/yamad07/IADA) | DA; segmentation |
|4. | ADDA-REPLAY |Adapting To Continuously Shifting Domains|[ICLR Workshop 2018](https://openreview.net/forum?id=BJsBjPJvf) | [No]() | DA; classification |
|5. | CANet |CANet: Class-Agnostic Segmentation Networks with Iterative Refinement and Attentive Few-Shot Learning|[CVPR 2019](https://arxiv.org/abs/1903.02351) | [No]() | few-shot; segmentation |
### Unread

| No. | Abb.| title | pdf | code | Brief| 
| :-: | :-: |:-: | :-: | :-: | :-:|
|1. | SPNet |Semantic Projection Network for Zero- and Few-Label Semantic Segmentation|[CVPR 2019](http://openaccess.thecvf.com/content_CVPR_2019/papers/Xian_Semantic_Projection_Network_for_Zero-_and_Few-Label_Semantic_Segmentation_CVPR_2019_paper.pdf) | [Pytorch](https://github.com/y2l/meta-transfer-learning-pytorch) | zero- and few-shot; segmentation |
|2. | MAML |Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks|[ICML 2017](https://arxiv.org/abs/1703.03400) | [Pytorch](https://github.com/dragen1860/MAML-Pytorch) | Meta-learning; classification |
|3. | OML |Online Meta-Learning|[ICML 2019](https://arxiv.org/abs/1902.08438) | [No]() | Online; Meta-learning; classification |
|4. | Meta-Sim |Meta-Sim: Learning to Generate Synthetic Datasets|[ICCV 2019 Oral](https://arxiv.org/abs/1904.11621) | [Empty](https://nv-tlabs.github.io/meta-sim/) | Generalization |
|5. | OMLA |Online Adaptation through Meta-Learning for Stereo Depth Estimation|[ArXiv](https://arxiv.org/abs/1904.08462) | [No]() | Generalization |
|6. | Reptile |On First-Order Meta-Learning Algorithms|[CoRR 2018](https://arxiv.org/abs/1803.02999) | [No]() | Meta-Learning |
|7. | CMA |Continuous Manifold Based Adaptation for Evolving Visual Domains|[CVPR 2014](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6909511) | [Matlab](https://github.com/sgxcyy/CMA-implementation) | Continuous Adaptation |
|8. | |Online Domain Adaptation by Exploiting Labeled Features and Pro-active Learning |[CoDS-COMAD, 2018 ](https://dl.acm.org/citation.cfm?id=3152507) | [No]() | Online Adaptation |
|9. | |Generalizing to Unseen Domains via Adversarial Data Augmentation |[NIPS 2018(camera ready)](https://arxiv.org/abs/1805.12018) | [No]() | Generalizing |
|10. | |Zero-Shot Deep Domain Adaptation |[ECCV 2018](https://arxiv.org/abs/1707.01922) | [No]() | Zero-shot |
|11. | |Meta-learning autoencoders for few-shot prediction |[No](https://arxiv.org/pdf/1807.09912.pdf) | [No]() | Few-shot |
|12. | UM-Adapt |UM-Adapt: Unsupervised Multi-Task Adaptation Using Adversarial Cross-Task Distillation| [ICCV, 2019](https://arxiv.org/pdf/1908.03884.pdf)|[]()||
|13. | | Lifelong Learning for Sentiment ClassiÔ¨Åcation |[No](https://arxiv.org/abs/1801.02808) | [No]() | Lifelong Learning |

# Few-shot-PaperReading

### Have Read


| No. | Abb.| title | pdf | code | Brief| 
| :-: | :-: |:-: | :-: | :-: | :-:|




### Unread

| No. | Abb.| title | pdf | code | Brief| 
| :-: | :-: |:-: | :-: | :-: | :-:|
|1. | EGNN |Edge-Labeling Graph Neural Network for Few-shot Learning|[CVPR 2019 Oral](https://arxiv.org/abs/1905.01436) | [Pytorch](https://github.com/khy0809/fewshot-egnn) | few-shot-learning; classification |
|2. | LaSO | Label-Set Operations networks for multi-label few-shot learning |[CVPR 2019 Oral](https://arxiv.org/abs/1902.09811) | [No]() | few-shot-learning; classification | 
|3. | RepMet | Representative-based metric learning for classification and few-shot object detection |[CVPR 2019 Oral](https://arxiv.org/abs/1806.04728) | [No]() | few-shot-learning; detection |
|4. | | RFew Shot Adaptive Faster R-CNN |[CVPR 2019 Oral](https://arxiv.org/abs/1903.09372) | [No]() | few-shot-learning; detection |
|5. | | Deep Tree Learning for Zero-shot Face Anti-Spoofing |[CVPR 2019 Oral](https://arxiv.org/abs/1904.02860) | [No]() | few-shot-learning; face Anti-Proofing |
|6. | | Few-Shot Learning with Localization in Realistic Settings |[CVPR 2019 Oral](https://arxiv.org/abs/1904.08502) | [No]() | few-shot-learning;|
|7. | | Doodle to Search: Practical Zero-Shot Sketch-based Image Retrieval |[CVPR 2019 Oral](https://arxiv.org/abs/1904.03451) | [No]() | few-shot-learning;|
|8. | | Zero-Shot Task Transfer |[CVPR 2019 Oral](https://arxiv.org/abs/1903.01092) | [No]() | few-shot-learning;Task Transfer|
|9. | | Generating Classification Weights with Graph Neural Networks for Few-Shot Learning |[CVPR 2019 Oral]() | [No]() | few-shot-learning;Classification|
|10. | | Gradient Matching Generative Networks for Zero-Shot Learning |[CVPR 2019 Oral](http://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Generative_Dual_Adversarial_Network_for_Generalized_Zero-Shot_Learning_CVPR_2019_paper.html) | [No]() | few-shot-learning;|
|11. | | Learning Inter-pixel Relations for Weakly Supervised Instance Segmentation |[CVPR 2019 Oral](https://arxiv.org/abs/1904.05044) | [No]() | few-shot-learning; Instance Segmentation|
|12. | | Unsupervised Person Image Generation with Semantic Parsing Transformation |[CVPR 2019](https://arxiv.org/abs/1904.03379) | [No]() | few-shot-learning;|
|13. | | Rethinking Knowledge Graph Propagation for Zero-Shot Learning|[CVPR 2019 Oral](https://arxiv.org/abs/1805.11724) | [No]() | few-shot-learning;|
|14. | | Generative Dual Adversarial Network for Generalized Zero-shot Learning |[CVPR 2019](https://arxiv.org/abs/1811.04857) | [No]() | few-shot-learning;|
|15. | | Hierarchical Disentanglement of Discriminative Latent Features for Zero-shot Learning |[CVPR 2019](https://arxiv.org/abs/1803.06731) | [No]() | few-shot-learning;|
|16. | | Spot and Learn: A Maximum-Entropy Image Patch Sampler for Few-Shot Classification |[CVPR 2019]() | [No]() | few-shot-learning;|
|17. | | Large-Scale Few-Shot Learning: Knowledge Transfer with Class Hierarchy |[CVPR 2019]() | [No]() | few-shot-learning;|
|18. | | Generalized Zero- and Few-Shot Learning via Aligned Variational Autoencoders |[CVPR 2019](https://arxiv.org/abs/1812.01784) | [No]() | few-shot-learning;|
|19. | | Dense Classification and Implanting for Few-shot Learning |[CVPR 2019](https://arxiv.org/abs/1903.05050) | [No]() | few-shot-learning;|
|20. | | On zero-shot recognition of generic objects |[CVPR 2019](https://arxiv.org/abs/1904.04957) | [No]() | few-shot-learning;|
|21. | | out-of-distribution detection for generalized zero-shot action recognition |[CVPR 2019](https://arxiv.org/abs/1904.08703) | [No]() | few-shot-learning;|
